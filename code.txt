import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

# 检查是否有可用的GPU，有则使用，没有则使用CPU
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(f'Using device: {device}')

# 图像预处理，包括归一化和转换为Tensor
transform = transforms.Compose([
    transforms.Resize((220, 220)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# 构建训练和测试数据集
train_dataset = datasets.ImageFolder(root='D:/图像分类/image/train', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

test_dataset = datasets.ImageFolder(root='D:/图像分类/image/test', transform=transform)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

class CustomResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1, downsample=None):
        super(CustomResidualBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.downsample = downsample
        if downsample is not None or in_channels != out_channels:
            self.downsample = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0, bias=False),
                nn.BatchNorm2d(out_channels)
            )

    def forward(self, x):
        residual = x if self.downsample is None else self.downsample(x)

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)

        out += residual
        out = self.relu(out)

        return out

class EncoderDecoderResNet(nn.Module):
    def __init__(self):
        super(EncoderDecoderResNet, self).__init__()
        # 编码器
        self.encoder1 = CustomResidualBlock(128, 64)  # 128 -> 64
        self.encoder2 = CustomResidualBlock(64, 32)   # 64 -> 32
        self.encoder3 = CustomResidualBlock(32, 16)   # 32 -> 16
        # 解码器
        self.decoder1 = CustomResidualBlock(16, 32)   # 16 -> 32
        self.decoder2 = CustomResidualBlock(32, 64)   # 32 -> 64
        self.decoder2 = CustomResidualBlock(64, 128)   # 64 -> 128

        # 可选择的上采样层 (不保证学习特征上采样, 只是空间维度上的放大)
        # 如果需要学习上采样过程，可以使用nn.ConvTranspose2d
        self.upsample = nn.ConvTranspose2d(scale_factor=2, mode='nearest')

    def forward(self, x):
        # 编码
        x = self.encoder1(x)
        x = self.upsample(x)
        x = self.encoder2(x)
        x = self.upsample(x)
        x = self.encoder3(x)
        # 解码
        x = self.upsample(x)
        x = self.decoder1(x)
        x = self.upsample(x)
        x = self.decoder2(x)        
        return x

# 定义损失函数和优化器
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 训练模型
num_epochs = 8
for epoch in range(num_epochs):
    model.train()
    for i, (images, labels) in enumerate(train_loader):
        images, labels = images.to(device), labels.to(device)
        
        # 前向传播
        outputs = model(images)
        loss = criterion(outputs, labels)
        
        # 反向传播和优化
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')

# 使用测试数据评估模型
model.eval()
all_preds = []
all_labels = []
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, preds = torch.max(outputs, 1)
        all_preds.extend(preds.view(-1).cpu().numpy())
        all_labels.extend(labels.view(-1).cpu().numpy())

# 计算每个类的准确率
class_correct = {classname: 0 for classname in test_loader.dataset.classes}
class_total = {classname: 0 for classname in test_loader.dataset.classes}
for label, prediction in zip(all_labels, all_preds):
    classname = test_loader.dataset.classes[label]
    if label == prediction:
        class_correct[classname] += 1
    class_total[classname] += 1

for classname, correct_count in class_correct.items():
    accuracy = 100 * float(correct_count) / class_total[classname]
    print("Accuracy for class {:5s} is: {:.1f} %".format(classname, accuracy))

# 绘制混淆矩阵
cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_loader.dataset.classes, yticklabels=test_loader.dataset.classes)
plt.title('Confusion Matrix')
plt.ylabel('True Class')
plt.xlabel('Predicted Class')
plt.show()

# 打印分类报告
print(classification_report(all_labels, all_preds, target_names=test_loader.dataset.classes))